README.md
markdown
# Projet : Classification avec Arbres de DÃ©cision et ForÃªts AlÃ©atoires

## ğŸ“‹ Description
Ce projet implÃ©mente des algorithmes de classification (Arbres de DÃ©cision et ForÃªts AlÃ©atoires) sur le dataset Forest Covertypes pour prÃ©dire le type de couverture forestiÃ¨re.

## ğŸ¯ Objectifs
- Mettre en Å“uvre l'algorithme des arbres de dÃ©cision
- PrÃ©parer et prÃ©traiter les donnÃ©es
- DÃ©finir des mÃ©triques pertinentes
- Comparer avec une baseline simple
- Optimiser les hyperparamÃ¨tres
- Analyser les rÃ©sultats et les limites

## ğŸ“Š Dataset
**Forest Covertypes** - UCI Machine Learning Repository
- **Ã‰chantillons** : 581,012
- **CaractÃ©ristiques** : 54 (10 quantitatives + 44 binaires)
- **Classes** : 7 types de couverture forestiÃ¨re
- **Source** : Roosevelt National Forest, Colorado

## ğŸ› ï¸ PrÃ©requis
- Python 3.8+
- Jupyter Notebook ou Google Colab

## ğŸ“¦ Installation
```bash
# Cloner le repository
git clone [repository-url]
cd [project-folder]

# Installer les dÃ©pendances
pip install -r requirements.txt
DÃ©pendances principales :
text
numpy>=1.21.0
pandas>=1.3.0
scikit-learn>=1.0.0
matplotlib>=3.5.0
seaborn>=0.11.0
scikit-plot>=0.3.7
plotly>=5.6.0
ğŸš€ ExÃ©cution
Ouvrir le notebook decision_trees_forest_covertypes.ipynb

ExÃ©cuter toutes les cellules dans l'ordre

Les rÃ©sultats seront affichÃ©s directement dans le notebook

Sur Google Colab :
TÃ©lÃ©charger le notebook

L'uploader sur Google Colab

ExÃ©cuter les cellules (les installations se font automatiquement)

ğŸ“ Structure du projet
text
project/
â”‚
â”œâ”€â”€ decision_trees_forest_covertypes.ipynb  # Notebook principal
â”œâ”€â”€ README.md                               # Documentation
â”œâ”€â”€ requirements.txt                        # DÃ©pendances
â”œâ”€â”€ models/                                 # ModÃ¨les sauvegardÃ©s
â”‚   â”œâ”€â”€ best_decision_tree.pkl
â”‚   â”œâ”€â”€ best_random_forest.pkl
â”‚   â””â”€â”€ scaler.pkl
â””â”€â”€ slides/                                 # PrÃ©sentation
    â””â”€â”€ presentation.pptx
ğŸ“ˆ MÃ©triques utilisÃ©es
Accuracy : Proportion de prÃ©dictions correctes

F1-score : Moyenne harmonique de prÃ©cision et rappel

Matrice de confusion : Analyse des erreurs par classe

Importance des caractÃ©ristiques : Identification des variables importantes

ğŸ§ª ModÃ¨les implÃ©mentÃ©s
Baseline : Classifier le plus frÃ©quent

Arbre de dÃ©cision : Avec optimisation des hyperparamÃ¨tres

ForÃªt alÃ©atoire : Avec recherche alÃ©atoire d'hyperparamÃ¨tres

ğŸ” MÃ©thodologie
Exploration : Analyse des donnÃ©es et distribution des classes

PrÃ©traitement : Normalisation et encodage

SÃ©paration : Train/Test split (80/20)

Baseline : Ã‰tablissement d'une performance de rÃ©fÃ©rence

EntraÃ®nement : ModÃ¨les avec paramÃ¨tres par dÃ©faut

Optimisation : Recherche d'hyperparamÃ¨tres

Ã‰valuation : MÃ©triques et visualisations

Analyse : InterprÃ©tation et limites

ğŸ“Š RÃ©sultats
ModÃ¨le	Accuracy	F1-score
Baseline	0.486	0.364
Arbre (dÃ©faut)	0.856	0.856
Arbre (optimisÃ©)	0.912	0.912
ForÃªt (dÃ©faut)	0.942	0.942
ForÃªt (optimisÃ©e)	0.953	0.953
ğŸ”§ HyperparamÃ¨tres optimaux
Arbre de dÃ©cision :
max_depth: 20

min_samples_split: 2

min_samples_leaf: 1

criterion: 'gini'

ForÃªt alÃ©atoire :
n_estimators: 200

min_samples_split: 2

min_samples_leaf: 1

max_depth: None

bootstrap: True

ğŸ“ InterprÃ©tation
CaractÃ©ristiques importantes : Ã‰lÃ©vation, pente, distance aux points d'eau

Classes difficiles : Certaines classes sont souvent confondues

Impact du prÃ©traitement : La normalisation amÃ©liore significativement les performances

âš ï¸ Limites identifiÃ©es
DÃ©sÃ©quilibre des classes affectant les performances sur les classes minoritaires

ComplexitÃ© computationnelle pour l'optimisation des hyperparamÃ¨tres

InterprÃ©tabilitÃ© rÃ©duite des forÃªts alÃ©atoires

Risque de surapprentissage avec des arbres trop profonds

ğŸ”® AmÃ©liorations possibles
Techniques de rÃ©-Ã©chantillonnage pour le dÃ©sÃ©quilibre

Essai de modÃ¨les de Gradient Boosting

RÃ©duction de dimensionnalitÃ© (PCA)

Validation croisÃ©e plus poussÃ©e

ğŸ“š RÃ©fÃ©rences
Breiman, L. (2001). Random Forests. Machine Learning, 45(1), 5-32.

Scikit-learn Documentation: https://scikit-learn.org/

UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/covertype

ğŸ‘¥ Auteurs
SOULEIMANI Mohamed Rayan , EL FATTAHI Wissal , OUHMIDOU Amine, BENABDESSADEK Dikra

Ecole Marocaine des Sciences de l'IngÃ©nieurs

ğŸ“„ Licence
Ce projet est sous licence MIT. Voir le fichier LICENSE pour plus de dÃ©tails.

